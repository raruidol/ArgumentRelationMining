Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic


{'mcc': 0.5370081183252575, 'acc': 0.7686717803794914, 'eval_loss': 1.5106809093401983}
{'mcc': 0.5370081183252575, 'acc': 0.7686717803794914, 'eval_loss': 1.5106809093401983}
Test F1-macro score: 0.6008791183400134
Converting to features started. Cache is not used.
{'mcc': 0.4180813308101039, 'acc': 0.6880517951736316, 'eval_loss': 2.089997439472764}
{'mcc': 0.4180813308101039, 'acc': 0.6880517951736316, 'eval_loss': 2.089997439472764}
MM2012 F1-macro score: 0.5240801391486237
Converting to features started. Cache is not used.
{'mcc': 0.32444927692773795, 'acc': 0.6080178173719376, 'eval_loss': 2.3822615444660187}
{'mcc': 0.32444927692773795, 'acc': 0.6080178173719376, 'eval_loss': 2.3822615444660187}
Bank F1-macro score: 0.4176429892206798
Converting to features started. Cache is not used.
{'mcc': 0.32129386880101335, 'acc': 0.6218809980806143, 'eval_loss': 2.400728483994802}
{'mcc': 0.32129386880101335, 'acc': 0.6218809980806143, 'eval_loss': 2.400728483994802}
Empire F1-macro score: 0.4502916820835904
Converting to features started. Cache is not used.
{'mcc': 0.4011243683455742, 'acc': 0.6514215080346106, 'eval_loss': 2.392832407584557}
{'mcc': 0.4011243683455742, 'acc': 0.6514215080346106, 'eval_loss': 2.392832407584557}
Money F1-macro score: 0.55012639313752
Converting to features started. Cache is not used.
{'mcc': 0.3071241490808353, 'acc': 0.6150943396226415, 'eval_loss': 2.577491971162649}
{'mcc': 0.3071241490808353, 'acc': 0.6150943396226415, 'eval_loss': 2.577491971162649}
Problem F1-macro score: 0.45963124358252005
Converting to features started. Cache is not used.
{'mcc': 0.3190940550645817, 'acc': 0.6101694915254238, 'eval_loss': 2.6806265115737915}
{'mcc': 0.3190940550645817, 'acc': 0.6101694915254238, 'eval_loss': 2.6806265115737915}
Welfare F1-macro score: 0.48063204816675953

train_args={
  "output_dir": "outputs/",
  "cache_dir": "cache/",

  "fp16": True,
  "fp16_opt_level": "O1",
  "max_seq_length": 256,
  "train_batch_size": 64,
  "eval_batch_size": 64,
  "gradient_accumulation_steps": 2,
  "num_train_epochs": 50,
  "weight_decay": 0,
  "learning_rate": 1e-5,
  "adam_epsilon": 1e-8,
  "warmup_ratio": 0.06,
  "warmup_steps": 120,
  "max_grad_norm": 1.0,
  "do_lower_case": True,

  "logging_steps": 50,
  "evaluate_during_training": False,
  "evaluate_during_training_steps": 2000,
  "evaluate_during_training_verbose": False,
  "use_cached_eval_features": False,
  "save_eval_checkpoints": False,
  "save_steps": 2000,
  "no_cache": False,
  "save_model_every_epoch": True,
  "tensorboard_dir": None,

  "overwrite_output_dir": True,
  "reprocess_input_data": True,
  
  "n_gpu": 2,
  "silent": True,
  "use_multiprocessing": True,

  "wandb_project": None,
  "wandb_kwargs": {},

  "use_early_stopping": True,
  "early_stopping_patience": 3,
  "early_stopping_delta": 0,

}

# Create a ClassificationModel
model = ClassificationModel('albert', 'albert-base-v2', num_labels=4, use_cuda=True, cuda_device=0, args=train_args)